{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Signal Detection\n",
    "## Semi-Automated Signal Detection for Annotation\n",
    "\n",
    "This notebook covers:\n",
    "- Detecting Bluetooth signals automatically\n",
    "- Generating preliminary bounding boxes\n",
    "- Creating YOLO format annotations\n",
    "- Manual verification workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from src.visualization import plot_spectrogram_with_detections\n",
    "\n",
    "print(\"✅ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "SPECTROGRAM_DIR = Path('../data/spectrograms')\n",
    "ANNOTATION_DIR = Path('../data/annotations')\n",
    "ANNOTATION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Signal classes\n",
    "SIGNAL_CLASSES = {\n",
    "    0: 'bluetooth',\n",
    "    1: 'wifi',\n",
    "    2: 'zigbee',\n",
    "    3: 'drone'\n",
    "}\n",
    "\n",
    "# Detection parameters\n",
    "INTENSITY_THRESHOLD = 180\n",
    "MAX_WIDTH = 15  # pixels\n",
    "MIN_HEIGHT = 30  # pixels\n",
    "\n",
    "print(f\"Classes: {list(SIGNAL_CLASSES.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Signal Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_narrow_vertical_signals(spectrogram, intensity_threshold=180, \n",
    "                                   max_width=15, min_height=30):\n",
    "    \"\"\"\n",
    "    Automatically detect Bluetooth-like signals for annotation assistance\n",
    "    \n",
    "    Returns:\n",
    "        List of bounding boxes in YOLO format\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(spectrogram, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Threshold high-intensity regions\n",
    "    _, binary = cv2.threshold(gray, intensity_threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary)\n",
    "    \n",
    "    bboxes = []\n",
    "    height, width = spectrogram.shape[:2]\n",
    "    \n",
    "    for i in range(1, num_labels):  # Skip background (0)\n",
    "        x, y, w, h, area = stats[i]\n",
    "        \n",
    "        # Filter for Bluetooth characteristics (narrow vertical)\n",
    "        if w <= max_width and h >= min_height:\n",
    "            # Convert to YOLO format (normalized)\n",
    "            x_center = (x + w/2) / width\n",
    "            y_center = (y + h/2) / height\n",
    "            w_norm = w / width\n",
    "            h_norm = h / height\n",
    "            \n",
    "            bboxes.append({\n",
    "                'class_id': 0,  # Bluetooth\n",
    "                'bbox': [x_center, y_center, w_norm, h_norm],\n",
    "                'confidence': area / (w * h)  # Density score\n",
    "            })\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def save_yolo_annotation(image_path, bboxes, output_dir):\n",
    "    \"\"\"Save YOLO format annotation file\"\"\"\n",
    "    image_name = Path(image_path).stem\n",
    "    annotation_file = Path(output_dir) / f\"{image_name}.txt\"\n",
    "    \n",
    "    with open(annotation_file, 'w') as f:\n",
    "        for bbox in bboxes:\n",
    "            class_id = bbox['class_id']\n",
    "            x, y, w, h = bbox['bbox']\n",
    "            f.write(f\"{class_id} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Detection on Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample spectrogram\n",
    "spec_files = sorted(SPECTROGRAM_DIR.glob('*.png'))\n",
    "\n",
    "if len(spec_files) > 0:\n",
    "    sample_file = spec_files[0]\n",
    "    img = cv2.imread(str(sample_file))\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect signals\n",
    "    bboxes = detect_narrow_vertical_signals(\n",
    "        img_rgb,\n",
    "        intensity_threshold=INTENSITY_THRESHOLD,\n",
    "        max_width=MAX_WIDTH,\n",
    "        min_height=MIN_HEIGHT\n",
    "    )\n",
    "    \n",
    "    print(f\"Detected {len(bboxes)} potential Bluetooth signals\")\n",
    "    \n",
    "    # Visualize\n",
    "    plot_spectrogram_with_detections(\n",
    "        img_rgb,\n",
    "        bboxes,\n",
    "        title=f\"Detections: {sample_file.name}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"⚠️ No spectrograms found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Process All Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "spec_files = sorted(SPECTROGRAM_DIR.glob('*.png'))\n",
    "total_detections = 0\n",
    "\n",
    "for spec_file in tqdm(spec_files, desc=\"Processing spectrograms\"):\n",
    "    img = cv2.imread(str(spec_file))\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect signals\n",
    "    bboxes = detect_narrow_vertical_signals(\n",
    "        img_rgb,\n",
    "        intensity_threshold=INTENSITY_THRESHOLD,\n",
    "        max_width=MAX_WIDTH,\n",
    "        min_height=MIN_HEIGHT\n",
    "    )\n",
    "    \n",
    "    # Save annotation\n",
    "    if len(bboxes) > 0:\n",
    "        save_yolo_annotation(spec_file, bboxes, ANNOTATION_DIR)\n",
    "        total_detections += len(bboxes)\n",
    "\n",
    "print(f\"\\n✅ Processed {len(spec_files)} spectrograms\")\n",
    "print(f\"Total detections: {total_detections}\")\n",
    "print(f\"Average detections per image: {total_detections/len(spec_files):.2f}\")\n",
    "print(f\"Annotations saved to {ANNOTATION_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count annotations\n",
    "annotation_files = sorted(ANNOTATION_DIR.glob('*.txt'))\n",
    "detections_per_file = []\n",
    "\n",
    "for annot_file in annotation_files:\n",
    "    with open(annot_file, 'r') as f:\n",
    "        num_detections = len(f.readlines())\n",
    "        detections_per_file.append(num_detections)\n",
    "\n",
    "if len(detections_per_file) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(detections_per_file, bins=20, edgecolor='black')\n",
    "    plt.xlabel('Number of Detections per Image')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Detections Across Spectrograms')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Manually verify and correct annotations using LabelImg or Roboflow\n",
    "2. Continue to notebook 05 for YOLO dataset preparation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
