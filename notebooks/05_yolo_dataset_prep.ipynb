{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - YOLO Dataset Preparation\n",
    "## Creating Train/Val/Test Splits and Training YOLO\n",
    "\n",
    "This notebook covers:\n",
    "- Creating train/val/test splits\n",
    "- Organizing YOLO directory structure\n",
    "- Creating data.yaml configuration\n",
    "- Training YOLOv8 model\n",
    "- Evaluation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "\n",
    "print(\"✅ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "SPECTROGRAM_DIR = Path('../data/spectrograms')\n",
    "ANNOTATION_DIR = Path('../data/annotations')\n",
    "DATASET_DIR = Path('../data/yolo_dataset')\n",
    "\n",
    "# Split ratios\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "# Signal classes\n",
    "SIGNAL_CLASSES = ['bluetooth', 'wifi', 'zigbee', 'drone']\n",
    "\n",
    "print(f\"Train: {TRAIN_RATIO*100}%, Val: {VAL_RATIO*100}%, Test: {TEST_RATIO*100}%\")\n",
    "print(f\"Classes: {SIGNAL_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_dataset_split(image_dir, annotation_dir, output_dir, \n",
    "                              train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Organize dataset into YOLO directory structure\n",
    "    \"\"\"\n",
    "    # Get all image files\n",
    "    image_files = sorted(Path(image_dir).glob(\"*.png\"))\n",
    "    print(f\"Found {len(image_files)} images\")\n",
    "    \n",
    "    # Filter images that have annotations\n",
    "    annotated_images = []\n",
    "    for img_file in image_files:\n",
    "        annot_file = Path(annotation_dir) / f\"{img_file.stem}.txt\"\n",
    "        if annot_file.exists():\n",
    "            annotated_images.append(img_file)\n",
    "    \n",
    "    print(f\"Found {len(annotated_images)} annotated images\")\n",
    "    \n",
    "    # Split dataset\n",
    "    train_files, temp_files = train_test_split(annotated_images, train_size=train_ratio, random_state=42)\n",
    "    val_files, test_files = train_test_split(temp_files, train_size=val_ratio/(val_ratio+test_ratio), random_state=42)\n",
    "    \n",
    "    splits = {\n",
    "        'train': train_files,\n",
    "        'val': val_files,\n",
    "        'test': test_files\n",
    "    }\n",
    "    \n",
    "    # Create directory structure and copy files\n",
    "    for split_name, files in splits.items():\n",
    "        split_dir = Path(output_dir) / split_name\n",
    "        (split_dir / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (split_dir / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for img_file in files:\n",
    "            # Copy image\n",
    "            shutil.copy(img_file, split_dir / 'images' / img_file.name)\n",
    "            \n",
    "            # Copy corresponding annotation\n",
    "            annot_file = Path(annotation_dir) / f\"{img_file.stem}.txt\"\n",
    "            if annot_file.exists():\n",
    "                shutil.copy(annot_file, split_dir / 'labels' / annot_file.name)\n",
    "    \n",
    "    print(f\"\\n✅ Dataset split created in {output_dir}\")\n",
    "    print(f\"Train: {len(train_files)}, Val: {len(val_files)}, Test: {len(test_files)}\")\n",
    "    \n",
    "    return len(train_files), len(val_files), len(test_files)\n",
    "\n",
    "# Execute split\n",
    "train_count, val_count, test_count = create_yolo_dataset_split(\n",
    "    SPECTROGRAM_DIR,\n",
    "    ANNOTATION_DIR,\n",
    "    DATASET_DIR,\n",
    "    TRAIN_RATIO,\n",
    "    VAL_RATIO,\n",
    "    TEST_RATIO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YOLO configuration file\n",
    "data_yaml = {\n",
    "    'path': str(DATASET_DIR.absolute()),\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'test': 'test/images',\n",
    "    'nc': len(SIGNAL_CLASSES),\n",
    "    'names': SIGNAL_CLASSES\n",
    "}\n",
    "\n",
    "yaml_path = DATASET_DIR / 'data.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "\n",
    "print(f\"✅ Created {yaml_path}\")\n",
    "print(\"\\nContents:\")\n",
    "print(yaml.dump(data_yaml, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Training parameters\n",
    "MODEL_SIZE = 'yolov8n'  # Options: yolov8n, yolov8s, yolov8m, yolov8l, yolov8x\n",
    "EPOCHS = 100\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "print(f\"Training {MODEL_SIZE} for {EPOCHS} epochs\")\n",
    "print(f\"Image size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = YOLO(f'{MODEL_SIZE}.pt')\n",
    "\n",
    "# Train\n",
    "results = model.train(\n",
    "    data=str(yaml_path),\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    device=0,  # GPU device (use 'cpu' for CPU training)\n",
    "    workers=4,\n",
    "    \n",
    "    # Optimization\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    \n",
    "    # Augmentation (safe for spectrograms)\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=0.0,  # No rotation\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    flipud=0.0,  # No vertical flip\n",
    "    fliplr=0.0,  # No horizontal flip\n",
    "    mosaic=1.0,\n",
    "    mixup=0.0,\n",
    "    \n",
    "    # Validation\n",
    "    val=True,\n",
    "    save_period=10,\n",
    "    \n",
    "    # Logging\n",
    "    project='../models',\n",
    "    name='rf_signal_detection',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = Path('../models/rf_signal_detection/weights/best.pt')\n",
    "model = YOLO(str(best_model_path))\n",
    "\n",
    "# Run validation\n",
    "metrics = model.val(data=str(yaml_path), split='test')\n",
    "\n",
    "print(f\"\\nmAP@0.5: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "print(f\"\\nPer-class metrics:\")\n",
    "for i, class_name in enumerate(SIGNAL_CLASSES):\n",
    "    print(f\"  {class_name}:\")\n",
    "    print(f\"    Precision: {metrics.box.p[i]:.4f}\")\n",
    "    print(f\"    Recall: {metrics.box.r[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Get test images\n",
    "test_images = sorted((DATASET_DIR / 'test/images').glob('*.png'))\n",
    "\n",
    "# Run inference on first few\n",
    "results = model.predict(\n",
    "    source=test_images[:6],\n",
    "    conf=0.25,\n",
    "    iou=0.45,\n",
    "    save=False\n",
    ")\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    img = result.plot()  # Draw predictions on image\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    axes[idx].imshow(img_rgb)\n",
    "    axes[idx].set_title(f\"Test Image {idx+1}\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training complete! The model is ready for deployment.\n",
    "\n",
    "Next steps:\n",
    "- Fine-tune hyperparameters\n",
    "- Collect more training data\n",
    "- Implement real-time inference pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
